{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# example of gradient checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.56064469 -0.83461649  0.33767547  1.95814571]\n",
      " [-0.69278564 -0.262563    0.78950613  0.57030876]]\n",
      "(array([[-0.61960527, -0.23802759,  1.85986063],\n",
      "       [-0.70880232,  0.02450578,  1.01494673]]), array([[-0.26532008, -0.40933374, -0.26829664,  0.43920952],\n",
      "       [-0.44996034, -0.33125269,  1.07550006, -2.17797381],\n",
      "       [ 0.04459285, -0.73676977, -0.17225984,  0.91946643]]), array([-0.91507787,  0.20319997,  0.74781545,  0.00178496]))\n",
      "[[-1.37839419 -0.23066992  1.81082878 -1.04379967]\n",
      " [-0.04655312 -0.1859081   0.18368152  0.00952235]\n",
      " [ 2.32692265  1.05713889 -3.51625517  1.59422529]]\n",
      "[[-1.37839419 -0.23066992  1.81082878 -1.04379967]\n",
      " [-0.04655312 -0.1859081   0.18368152  0.00952235]\n",
      " [ 2.32692265  1.05713889 -3.51625517  1.59422529]]\n"
     ]
    }
   ],
   "source": [
    "# gradient checking: compare the analytical gradient with the numerical gradient\n",
    "# taking the affine layer as an example\n",
    "from gradient_check import eval_numerical_gradient_array\n",
    "import numpy as np\n",
    "from layers import *\n",
    "N = 2\n",
    "D = 3\n",
    "M = 4\n",
    "x = np.random.normal(size=(N, D))\n",
    "w = np.random.normal(size=(D, M))\n",
    "b = np.random.normal(size=(M, ))\n",
    "dout = np.random.normal(size=(N, M))\n",
    "\n",
    "\n",
    "# do a forward pass first\n",
    "out, cache = affine_forward(x, w, b)\n",
    "print(out)\n",
    "print(cache)\n",
    "# check grad f/grad w, the [0] below gets the output out of the (output, cache) original output\n",
    "f=lambda w: affine_forward(x, w, b)[0]\n",
    "# compute the analytical gradient you wrote, [1] get the dw out of the (dx, dw, db) original output\n",
    "grad = affine_backward(dout, cache)[1]\n",
    "# compute the numerical gradient using the provided utility function\n",
    "ngrad = eval_numerical_gradient_array(f, w, dout)\n",
    "print(grad)\n",
    "print(ngrad)\n",
    "# they should be similar enough within some small error tolerance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# example of training a network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: put the path to your 'hw6_mds189', which should contain a 'trainval' and 'test' directory\n",
    "path = \"C:\\\\Users\\\\EndlessWormhole\\\\Desktop\\\\Spring 2019\\\\CS 189\\\\hw6\\\\mds_189\\\\trainval\"\n",
    "from data_utils import load_mds189\n",
    "# load the dataset\n",
    "debug = False  # OPTIONAL: you can change this to True for debugging *only*. Your reported results must be with debug = False\n",
    "feat_train, label_train, feat_val, label_val = load_mds189(path,debug)\n",
    "from solver import Solver\n",
    "from classifiers.fc_net import FullyConnectedNet\n",
    "from classifiers.fc_net_general import FullyConnectedNetGeneral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "      'X_train': feat_train,\n",
    "      'y_train': label_train,\n",
    "      'X_val': feat_val,\n",
    "      'y_val': label_val}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\EndlessWormhole\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:595: DataConversionWarning: Data with input dtype int32 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "C:\\Users\\EndlessWormhole\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:595: DataConversionWarning: Data with input dtype int32 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "#training = np.concatenate(feat_train, label_train)\n",
    "#validation = np.concatenate(feat_val, label_val)\n",
    "training = scaler.fit_transform(feat_train, label_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['X_train'] = training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\EndlessWormhole\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:595: DataConversionWarning: Data with input dtype int32 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "validation = scaler.transform(feat_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['X_val'] = validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Iteration 1 / 360) loss: 7.595965\n",
      "(Epoch 0 / 10) train acc: 0.058000; val_acc: 0.039167\n",
      "(Epoch 1 / 10) train acc: 0.496000; val_acc: 0.484167\n",
      "(Epoch 2 / 10) train acc: 0.613000; val_acc: 0.604167\n",
      "(Iteration 101 / 360) loss: 18.452124\n",
      "(Epoch 3 / 10) train acc: 0.686000; val_acc: 0.678333\n",
      "(Epoch 4 / 10) train acc: 0.722000; val_acc: 0.729167\n",
      "(Epoch 5 / 10) train acc: 0.814000; val_acc: 0.792500\n",
      "(Iteration 201 / 360) loss: 28.118461\n",
      "(Epoch 6 / 10) train acc: 0.850000; val_acc: 0.827500\n",
      "(Epoch 7 / 10) train acc: 0.890000; val_acc: 0.850000\n",
      "(Epoch 8 / 10) train acc: 0.896000; val_acc: 0.869167\n",
      "(Iteration 301 / 360) loss: 36.046400\n",
      "(Epoch 9 / 10) train acc: 0.908000; val_acc: 0.880000\n",
      "(Epoch 10 / 10) train acc: 0.923000; val_acc: 0.885833\n"
     ]
    }
   ],
   "source": [
    "# TODO: fill out the hyperparamets\n",
    "hyperparams = {'lr_decay': 0.95,\n",
    "               'num_epochs': 10,\n",
    "               'batch_size': 100,\n",
    "               'learning_rate': 0.1\n",
    "              }\n",
    "\n",
    "# TODO: fill out the number of units in your hidden layers\n",
    "hidden_dim = [10, 5] # this should be a list of units for each hiddent layer\n",
    "\n",
    "model = FullyConnectedNet(input_dim=75,\n",
    "                          hidden_dim=hidden_dim)\n",
    "solver = Solver(model, data,\n",
    "                update_rule='sgd',\n",
    "                optim_config={\n",
    "                  'learning_rate': hyperparams['learning_rate'],\n",
    "                },\n",
    "                lr_decay=hyperparams['lr_decay'],\n",
    "                num_epochs=hyperparams['num_epochs'], \n",
    "                batch_size=hyperparams['batch_size'],\n",
    "                print_every=100)\n",
    "solver.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'hidden_dim' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-f621eef303ab>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m general_model = FullyConnectedNetGeneral(input_dim=75,\n\u001b[1;32m----> 2\u001b[1;33m                           hidden_dim=hidden_dim)\n\u001b[0m\u001b[0;32m      3\u001b[0m solver = Solver(general_model, data,\n\u001b[0;32m      4\u001b[0m                 \u001b[0mupdate_rule\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'sgd'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m                 optim_config={\n",
      "\u001b[1;31mNameError\u001b[0m: name 'hidden_dim' is not defined"
     ]
    }
   ],
   "source": [
    "general_model = FullyConnectedNetGeneral(input_dim=75,\n",
    "                          hidden_dim=hidden_dim)\n",
    "hyperparams = {'lr_decay': 0.95,\n",
    "               'num_epochs': 10,\n",
    "               'batch_size': 100,\n",
    "               'learning_rate': 0.1\n",
    "              }\n",
    "hidden_dim = [10, 5]\n",
    "solver = Solver(general_model, data,\n",
    "                update_rule='sgd',\n",
    "                optim_config={\n",
    "                  'learning_rate': hyperparams['learning_rate'],\n",
    "                },\n",
    "                lr_decay=hyperparams['lr_decay'],\n",
    "                num_epochs=hyperparams['num_epochs'], \n",
    "                batch_size=hyperparams['batch_size'],\n",
    "                print_every=100)\n",
    "solver.train()\n",
    "#this is for a 4 layer general model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
