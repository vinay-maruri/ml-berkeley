{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils import data\n",
    "from mds189 import Mds189\n",
    "import numpy as np\n",
    "from skimage import io, transform\n",
    "#import ipdb\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "import torchvision.models as models\n",
    "from PIL import Image\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "start = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions for loading images.\n",
    "def pil_loader(path):\n",
    "    # open path as file to avoid ResourceWarning (https://github.com/python-pillow/Pillow/issues/835)\n",
    "    with open(path, 'rb') as f:\n",
    "        img = Image.open(f)\n",
    "        return img.convert('RGB')\n",
    "\n",
    "def accimage_loader(path):\n",
    "    import accimage\n",
    "    try:\n",
    "        return accimage.Image(path)\n",
    "    except IOError:\n",
    "        # Potentially a decoding problem, fall back to PIL.Image\n",
    "        return pil_loader(path)\n",
    "\n",
    "def default_loader(path):\n",
    "    from torchvision import get_image_backend\n",
    "    if get_image_backend() == 'accimage':\n",
    "        return accimage_loader(path)\n",
    "    else:\n",
    "        return pil_loader(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flag for whether you're training or not\n",
    "is_train = True\n",
    "is_key_frame = True # TODO: set this to false to train on the video frames, instead of the key frames\n",
    "model_to_load = 'model.ckpt' # This is the model to load during testing, if you want to eval a previously-trained model.\n",
    "\n",
    "# CUDA for PyTorch\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
    "#cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters for data loader\n",
    "params = {'batch_size': 32,  # TODO: fill in the batch size. often, these are things like 32,64,128,or 256\n",
    "          'shuffle': True,\n",
    "          'num_workers': 2 \n",
    "          }\n",
    "# TODO: Hyper-parameters\n",
    "num_epochs = 20\n",
    "learning_rate = 0.001\n",
    "# NOTE: depending on your optimizer, you may want to tune other hyperparameters as well\n",
    "\n",
    "# Datasets\n",
    "# TODO: put the path to your train, test, validation txt files\n",
    "if is_key_frame:\n",
    "    label_file_train =  './dataloader_files/keyframe_data_train.txt'\n",
    "    label_file_val  =  './dataloader_files/keyframe_data_val.txt'\n",
    "    # NOTE: the kaggle competition test data is only for the video frames, not the key frames\n",
    "    # this is why we don't have an equivalent label_file_test with keyframes\n",
    "else:\n",
    "    label_file_train = './dataloader_files/videoframe_data_train.txt'\n",
    "    label_file_val = './dataloader_files/videoframe_data_val.txt'\n",
    "    label_file_test = './dataloader_files/videoframe_data_test.txt'\n",
    "\n",
    "# TODO: you should normalize based on the average image in the training set. This shows \n",
    "# an example of doing normalization\n",
    "mean = [0.5, 0.5, 0.5]\n",
    "std = [0.5, 0.5, 0.5]\n",
    "# TODO: if you want to pad or resize your images, you can put the parameters for that below.\n",
    "\n",
    "# Generators\n",
    "# NOTE: if you don't want to pad or resize your images, you should delete the Pad and Resize\n",
    "# transforms from all three _dataset definitions.\n",
    "train_dataset = Mds189(label_file_train,loader=default_loader,transform=transforms.Compose([\n",
    "                                               transforms.ToTensor(),\n",
    "                                               transforms.Normalize(mean, std)\n",
    "                                           ]))\n",
    "train_loader = data.DataLoader(train_dataset, **params)\n",
    "\n",
    "val_dataset = Mds189(label_file_val,loader=default_loader,transform=transforms.Compose([\n",
    "                                               transforms.ToTensor(),\n",
    "                                               transforms.Normalize(mean, std)\n",
    "                                           ]))\n",
    "val_loader = data.DataLoader(val_dataset, **params)\n",
    "\n",
    "if not is_key_frame:\n",
    "    test_dataset = Mds189(label_file_test,loader=default_loader,transform=transforms.Compose([\n",
    "                                                   transforms.ToTensor(),\n",
    "                                                   transforms.Normalize(mean, std)\n",
    "                                               ]))\n",
    "    test_loader = data.DataLoader(test_dataset, **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: one way of defining your model architecture is to fill in a class like NeuralNet()\n",
    "# NOTE: you should not overwrite the models you try whose performance you're keeping track of.\n",
    "#       one thing you could do is have many different model forward passes in class NeuralNet()\n",
    "#       and then depending on which model you want to train/evaluate, you call that model's\n",
    "#       forward pass. this strategy will save you a lot of time in the long run. the last thing\n",
    "#       you want to do is have to recode the layer structure for a model (whose performance\n",
    "#       you're reporting) because you forgot to e.g., compute the confusion matrix on its results\n",
    "#       or visualize the error modes of your (best) model\n",
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        # you can define some common layers, for example: \n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv1 = nn.Conv2d(3, 16, 3, stride = 2, padding = 1) # you should review the definition of nn.Conv2d online\n",
    "        self.conv2 = nn.Conv2d(16, 32, 3, stride = 2, padding = 1)\n",
    "        self.conv3 = nn.Conv2d(32, 64, 3, stride = 2, padding = 1)\n",
    "        self.conv4 = nn.Conv2d(64, 128, 3, stride = 2, padding = 1)\n",
    "        # note: input_dimensions and output_dimensions are not defined, they\n",
    "        # are placeholders to show you what arguments to pass to nn.Linear \n",
    "        self.fc1 = nn.Linear(256, 32)\n",
    "        self.fc2 = nn.Linear(32, 8)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # now you can use the layers you defined, to write the forward pass, i.e.,\n",
    "        # network architecture for your model\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        x = self.pool(F.relu(self.conv4(x)))\n",
    "        x = x.view(-1, np.prod(x.shape[1:]))\n",
    "        # Tensors need to be reshaped before going into an fc layer\n",
    "        # the -1 will correspond to the batch size\n",
    "        # x -> fc (affine) layer -> relu\n",
    "        x = F.relu(self.fc1(x))\n",
    "        print(\"relu(fc1): \" + str(x.shape))\n",
    "        x = self.fc2(x)\n",
    "        print(\"fc2: \" + str(x.shape))\n",
    "        return x\n",
    "\n",
    "model = NeuralNet().to(device)\n",
    "\n",
    "# if we're only testing, we don't want to train for any epochs, and we want to load a model\n",
    "if not is_train:\n",
    "    num_epochs = 0\n",
    "    model.load_state_dict(torch.load('model.ckpt'))\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = torch.nn.CrossEntropyLoss() #TODO: define your loss here. hint: should just require calling a built-in pytorch layer.\n",
    "# NOTE: you can use a different optimizer besides Adam, like RMSProp or SGD, if you'd like\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "# Loop over epochs\n",
    "print('Beginning training..')\n",
    "total_step = len(train_loader)\n",
    "loss_list = []\n",
    "for epoch in range(num_epochs):\n",
    "    # Training\n",
    "    print('epoch {}'.format(epoch))\n",
    "    for i, (local_batch,local_labels) in enumerate(train_loader):\n",
    "        # Transfer to GPU\n",
    "        local_ims, local_labels = local_batch.to(device), local_labels.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model.forward(local_ims)\n",
    "        loss = criterion(outputs, local_labels)\n",
    "        # TODO: maintain a list of your losses as a function of number of steps\n",
    "        #       because we ask you to plot this information\n",
    "        # NOTE: if you use Google Colab's tensorboard-like feature to visualize\n",
    "        #       the loss, you do not need to plot it here. just take a screenshot\n",
    "        #       of the loss curve and include it in your write-up.\n",
    "        loss_list.append(loss.item())\n",
    "\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if (i+1) % 4 == 0:\n",
    "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'\n",
    "                   .format(epoch+1, num_epochs, i+1, total_step, loss.item()))\n",
    "\n",
    "end = time.time()\n",
    "print('Time: {}'.format(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = np.arange(len(loss_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(xs, loss_list)\n",
    "plt.title('Training loss curve as a function of steps.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Beginning validation..')\n",
    "total_step = len(val_loader)\n",
    "loss_list2 = []\n",
    "for epoch in range(num_epochs):\n",
    "    # Training\n",
    "    print('epoch {}'.format(epoch))\n",
    "    for i, (local_batch,local_labels) in enumerate(val_loader):\n",
    "        # Transfer to GPU\n",
    "        local_ims, local_labels = local_batch.to(device), local_labels.to(device)\n",
    "        # Forward pass\n",
    "        outputs = model.forward(local_ims)\n",
    "        loss = criterion(outputs, local_labels)\n",
    "        # TODO: maintain a list of your losses as a function of number of steps\n",
    "        #       because we ask you to plot this information\n",
    "        # NOTE: if you use Google Colab's tensorboard-like feature to visualize\n",
    "        #       the loss, you do not need to plot it here. just take a screenshot\n",
    "        #       of the loss curve and include it in your write-up.\n",
    "        loss_list2.append(loss.item())\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if (i+1) % 4 == 0:\n",
    "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'\n",
    "                   .format(epoch+1, num_epochs, i+1, total_step, loss.item()))\n",
    "\n",
    "end = time.time()\n",
    "print('Time: {}'.format(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs2 = np.arange(len(loss_list2))\n",
    "plt.plot(xs2, loss_list2)\n",
    "plt.title('Validation loss curve as a function of number of steps.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the model\n",
    "# In test phase, we don't need to compute gradients (for memory efficiency)\n",
    "print('Beginning Testing..')\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    predicted_list = []\n",
    "    groundtruth_list = []\n",
    "    for (local_batch,local_labels) in val_loader:\n",
    "        # Transfer to GPU\n",
    "        local_ims, local_labels = local_batch.to(device), local_labels.to(device)\n",
    "\n",
    "        outputs = model.forward(local_ims)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += local_labels.size(0)\n",
    "        predicted_list.extend(predicted)\n",
    "        groundtruth_list.extend(local_labels)\n",
    "        correct += (predicted == local_labels).sum().item()\n",
    "\n",
    "    print('Accuracy of the network on the {} test images: {} %'.format(total, 100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at some things about the model results..\n",
    "# convert the predicted_list and groundtruth_list Tensors to lists\n",
    "pl = [p.cpu().numpy().tolist() for p in predicted_list]\n",
    "gt = [p.cpu().numpy().tolist() for p in groundtruth_list]\n",
    "\n",
    "# TODO: use pl and gt to produce your confusion matrices\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(gt, pl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view the per-movement accuracy\n",
    "label_map = ['reach','squat','inline','lunge','hamstrings','stretch','deadbug','pushup']\n",
    "for id in range(len(label_map)):\n",
    "    print('{}: {}'.format(label_map[id],sum([p and g for (p,g) in zip(np.array(pl)==np.array(gt),np.array(gt)==id)])/(sum(np.array(gt)==id)+0.)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: you'll need to run the forward pass on the kaggle competition images, and save those results to a csv file.\n",
    "if not is_key_frame:\n",
    "    # your code goes here!\n",
    "    pass\n",
    "\n",
    "# Save the model checkpoint\n",
    "torch.save(model.state_dict(), 'model.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_file_test = './dataloader_files/videoframe_data_test.txt'\n",
    "test_dataset = Mds189(label_file_test,loader=default_loader,transform=transforms.Compose([\n",
    "                                                   transforms.ToTensor(),\n",
    "                                                   transforms.Normalize(mean, std)\n",
    "                                               ]))\n",
    "test_loader = data.DataLoader(test_dataset, **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Beginning Testing..')\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    predicted_list = []\n",
    "    groundtruth_list = []\n",
    "    for (local_batch,local_labels) in test_loader:\n",
    "        # Transfer to GPU\n",
    "        local_ims, local_labels = local_batch.to(device), local_labels.to(device)\n",
    "        outputs = model.forward(local_ims)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += local_labels.size(0)\n",
    "        predicted_list.extend(predicted)\n",
    "        groundtruth_list.extend(local_labels)\n",
    "        correct += (predicted == local_labels).sum().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl = [p.cpu().numpy().tolist() for p in predicted_list]\n",
    "label_map = ['reach','squat','inline','lunge','hamstrings','stretch','deadbug','pushup']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('your_predictions.csv', 'w') as f:\n",
    "    for item in pl:\n",
    "        f.write(\"%s\\n\" % item)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
